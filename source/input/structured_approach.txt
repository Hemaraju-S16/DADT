Technical Specification: Deterministic Analytical Detail Transfer (DADT)

Executive Summary

The Deterministic Analytical Detail Transfer (DADT) framework is a rigorous, non-iterative analytical pipeline designed to refine coarse three-dimensional (3D) meshes by integrating high-fidelity depth diffusion data derived from the Marigold model. This methodology intentionally eschews conventional iterative optimization, which can suffer from "drift" and excessive computational overhead, as well as stochastic gradient-based fitting techniques that often introduce non-deterministic artifacts. Instead, it leverages foundational geometric principles, including orthographic projection consistency, two-dimensional silhouette warping, polynomial depth alignment, and frequency-domain noise suppression.

The system is engineered for manufacturing-grade precision within 2.5D and 3D relief applications, such as the production of numismatic artifacts, high-end jewelry, and precision mechanical components. In these industrial contexts, the exclusion of geometric "hallucinations," speculative occluded views, and multi-view inconsistencies is paramount. By conceptualizing the refinement process as a single-pass analytical transfer, DADT ensures that all topographic modifications remain mathematically traceable to verifiable signals within the source imagery, providing a robust "source of truth" for physical fabrication processes like CNC milling or 3D printing.

0. Global Conventions and Definitions

G1: Canonical Coordinate Frame

Chirality: The system operates within a standard right-handed Cartesian coordinate frame.

Axes Orientation: The $+Y$ axis denotes the vertical (body) vector; the $+X$ axis represents the horizontal (lateral) vector; and the $+Z$ axis signifies the forward-facing (camera/depth) vector. This orientation ensures that "forward" is positive depth toward the viewer.

Mapping Correspondence: The image origin $(0,0)$ at the top-left corner is mapped to 3D space such that pixel-Y aligns with mesh-Y. This spatial alignment ensures that standard UV mapping and rasterization pipelines interface seamlessly with the geometric environment without requiring complex coordinate transformations or manual axis swapping.

Architectural Compatibility: The system maintains full compatibility with the conventions established by TripoSR; consequently, single-image reconstructions are naturally oriented with depth represented along the $Z$ axis, minimizing the need for initial rotational alignment or manual orientation corrections.

G2: Visibility and Projection

Rasterization Methodology: Visibility and vertex-pixel correspondences are determined via hardware-accelerated Z-buffer rasterization at a high resolution of $768 \times 768$ pixels. This resolution provides a dense sampling grid appropriate for capturing fine-grained surface variations.

First-Hit Heuristic: A visibility mask is generated by comparing vertex Z-depth against the rendered depth buffer. Only vertices within a stringent depth tolerance of $\epsilon = 10^{-4}$ are designated for refinement. This "first-hit" policy is critical in preventing "ghosting" artifacts—where displacement is erroneously applied to back-facing or internal surfaces—as well as the unintended deformation of occluded geometry, such as the posterior side of a garment or an obscured limb.

Displacement Vector: All topographic refinements are applied exclusively along the global $+Z$ axis. This orthographic displacement precludes perspective-induced radial distortion and "fanning" effects, thereby maintaining the structural integrity of the relief sculpture relative to the camera plane. This is essential for applications like coin-making, where the "strike" must be perpendicular to the surface.

1. Stage 0: Canonical Foundation and Alignment

1.1 Mesh Normalization

Scale: The principal axis (either $X$ or $Y$) of the bounding box is normalized to a value of $1.0$, establishing a "unit cube" workspace that simplifies subsequent mathematical operations and ensures consistent behavior across models of varying original scales.

Translation: The mesh is translated such that the centroid of the bounding box coincides with the world origin $(0,0,0)$. This central alignment facilitates symmetrical processing and consistent windowing in later stages.

Data Preservation: Original Euclidean edge lengths ($L_{orig}$) are cached in a persistent buffer to serve as structural constraints for subsequent safety limiters. This ensures that the underlying topology remains within a valid physical envelope during displacement, effectively acting as a "geometric memory" of the original coarse structure.

1.2 Mesh Subdivision (Geometric Capacity)

Methodology: Loop Subdivision is employed, typically executed for two iterations. Loop subdivision is chosen for its ability to produce smooth surfaces while strictly respecting the original triangular topology.

Rationale: Standard coarse meshes generally comprise $5,000$ to $10,000$ vertices, which lack the requisite vertex density to accommodate the high-frequency topographic signals provided by Marigold (e.g., hair strands, fine fabric wrinkles). Subdivision increases this density to align with the $768$-pixel grid, achieving a vertex resolution of approximately $1.3\text{mm}$ at the unit scale.

Interpolation: The subdivision process utilizes an interpolating mode to preserve the original surface silhouette while enhancing the sampling resolution of the geometric faces. This ensures that the refinement process has sufficient "geometric real estate" to manifest complex details without pixel-stepping or aliasing artifacts.

1.3 Mask-Warp Alignment (Topological Synchronization)

This stage establishes absolute pixel-to-vertex correspondence prior to depth transfer, ensuring the 2D signal from the image aligns with the 3D structure of the coarse mesh.

Segmentation: The input foreground mask is extracted via $M_{in} = \text{segment}(I_{raw})$, using a robust segmentation model to isolate the primary subject.

Transformation: The raw RGB data and associated mask are cropped to their respective tight bounding boxes and scaled into a $768 \times 768$ canvas ($I_{centered}$, $M_{centered}$), preserving the original aspect ratio through appropriate padding. This centering provides a standardized input for the warping engine.

Template Generation: A $0^\circ$ azimuth/elevation silhouette ($M_{mesh}$) is rendered via the global canonical camera, representing the "target" shape that the input image must conform to.

Warp Computation: A low-frequency Thin Plate Spline (TPS) warp ($W$) is computed to align the boundaries of $M_{centered}$ with $M_{mesh}$. A $10 \times 10$ control grid is utilized to ensure global shape alignment (e.g., matching the width of a face or the slope of a shoulder) while preventing the distortion of high-frequency internal features.

Execution: The warp is applied to both RGB and mask data ($I_{aligned} = W(I_{centered})$; $M_{aligned} = W(M_{centered})$), ensuring rigorous geometric alignment between the photographic source and the 3D model. This ensures that a pixel representing a "nose" in the image truly corresponds to the "nose" vertices on the mesh.

2. Stage 1: Depth Sanitization and Metric Alignment

1.1 Normal Stabilization and Surface Healing

The diffusion process utilized by Marigold, while highly detailed, is prone to "micro-flips" and high-frequency orientation noise within the normal maps due to its stochastic nature.

Bilateral Filtering: A $5 \times 5$ bilateral filter ($\sigma_s=2.0, \sigma_r=0.1$) is applied to the normal map. This stabilizes orientations while preserving critical structural edges (e.g., the ridge of a nose or sharp fabric folds) by weighting neighbors based on both spatial distance and orientation similarity.

Guided Inpainting: In regions characterized by high uncertainty or invalid depth values ("black holes"), depth values are inpainted by propagating data from reliable adjacent pixels along the vectors defined by the stabilized normals. For example, if a dark hair region has missing depth, the surrounding normals guide a smooth continuation of the scalp's curvature into the void.

1.2 Stage 1.45: Frequency-Sanitized Depth (The Reality Filter)

Guided Filtering: The stabilized normal map ($N_{stable}$) serves as a guidance image for depth map filtering. This facilitates the differentiation between structural signals (depth changes corresponding to verified normal changes) and stochastic diffusion noise. It ensures that depth variations without corresponding normal support are smoothed away.

Nyquist Suppression: Details exceeding the frequency threshold defined by vertex spacing (approximately $1.1\text{mm}$ to $1.5\text{mm}$) are suppressed. This ensures the mesh remains manufacturable; details smaller than the milling bit or printer nozzle resolution are treated as noise.

Gradient Clamping: Depth gradients ($\nabla D$) are clamped at a $3\sigma$ threshold to eliminate isolated vertex spikes. This prevents the "pincushion" effect where single pixels move excessively relative to their neighbors.

1.3 Polynomial Depth Mapping (Relative to Metric)

Marigold outputs relative depth values in the range $[0,1]$, which must be accurately mapped to the absolute metric depth of the coarse mesh.

The $k=3$ Rationale: A third-degree polynomial is selected to provide three degrees of nonlinear freedom, addressing three discrete distortion axes common in diffusion depth:

Linear Term ($a_1$): Correction of global scaling and depth extent (e.g., the overall "thickness" of the object).

Quadratic Term ($a_2$): Mitigation of parabolic bias, addressing the "ballooning" or "flattening" effect inherent in diffusion-based predictions where the center of the image is often pushed too far forward.

Cubic Term ($a_3$): Compensation for perspective-to-orthographic compression and tilt-plane artifacts, ensuring that depth remains consistent even if the source photo was taken at a slight angle.

Optimization: The mapping function $D_{metric} = a_0 + a_1 D_{rel} + a_2 D_{rel}^2 + a_3 D_{rel}^3$ is solved via Linear Least Squares on the $M_{aligned}$ foreground pixels to find the optimal coefficients $(a_0 \dots a_3)$. This provides a globally optimal fit that respects the coarse mesh's large-scale proportions while adopting Marigold's local details.

3. Stage 2: Sliding-Window Detail Sampling

2.1 Spatial Partitioning

The $768 \times 768$ coordinate space is partitioned into a $4 \times 4$ grid of $384 \times 384$ pixel windows. This provides a $2\times$ magnification over the global perspective, allowing for more granular detail extraction in areas like the eyes or intricate jewelry patterns.

A $25\%$ overlap (amounting to $96$ pixels) is maintained between adjacent windows to ensure seamless topographic transitions and prevent boundary artifacts or "seams" in the final geometry.

2.2 Mask-Driven Activation

Windows are activated only if they encompass more than a threshold of foreground pixels (typically $> 500$ pixels). This heuristic focuses geometric refinement exclusively on the subject and prevents the propagation of background noise or unnecessary computation in empty regions. For a portrait, windows covering the shoulders and face activate, while those in the upper corners remain dormant.

2.3 Blending Methodology

For vertices whose projections occupy $K$ active overlapping windows, the raw $\Delta D$ values are extracted and averaged: $\Delta D = \frac{1}{K} \sum \Delta D_i$. The use of a consistent orthographic ray direction across all windows permits equal-weighted averaging without complex feathering, as the displacement vectors are parallel. This ensures that transition zones between windows remain smooth and continuous.

4. Stage 3 & 4: Reliability and Geometric Safety

4.1 Trust Filtering

Visibility Gating: $\Delta D$ is set to zero for all occluded vertices, ensuring only the "first surface" visible to the camera is modified.

Normal Suppression: Displacement is modulated by a weight $w_n = (\text{dot}(N_{vertex}, [0,0,1]))^2$. This weight reduces the trust assigned to depth signals at grazing angles (surfaces nearly parallel to the camera ray). For example, the side of a nose or a sharp cheekbone receives less displacement to prevent geometric "explosions" or tearing at the silhouette edges.

Uncertainty Integration: The final displacement is weighted by $(1 - U_{raw})$, where $U_{raw}$ represents the normalized uncertainty map provided by the Marigold model. This ensures that the mesh remains unchanged in areas where the AI model is "guessing."

4.2 Edge-Length Constraint (Structural Safety Limiter)

A hard physical constraint is enforced: no edge may exceed $2.0\times$ its original cached length ($L_{orig}$). This is vital for maintaining manifold integrity.

Predictive Scaling: For each vertex update, the system anticipates the resultant edge lengths. If a proposed movement would stretch an edge beyond the limit (e.g., pulling a shirt fold so far it "tears" away from the body), the displacement magnitude is proportionally scaled down to maintain mesh integrity. This maintains the "structural fabric" of the model.

4.3 Curvature-Aware Smoothing

Conventional Laplacian smoothing is often indiscriminate, eroding high-frequency structural details. DADT modulates Laplacian intensity based on the mean curvature ($H$) of the coarse mesh.

Adaptive Denoising: The smoothing weight follows the function $\exp(-\alpha |H|)$. In high-curvature areas (e.g., sharp folds, ridges, facial features), smoothing is suppressed to keep details crisp. In low-curvature surfaces (e.g., flat fabric, smooth skin), smoothing is increased to effectively denoise diffusion artifacts, resulting in a clean, "sculpted" aesthetic.

5. Stage 5: Metric Output and Export

5.1 One-Shot Execution

The refinement is finalized through a single analytical update along the Z-axis. Because the pipeline is deterministic, there is no need for repeated passes.

$$v_{new} = v_{old} + [0, 0, (\Delta D_{blended} \cdot w_n \cdot w_u \cdot s_{limiter})]$$

This ensures that the result is repeatable and mathematically sound, with each vertex moving exactly to its determined physical position.

5.2 Post-Processing and Scaling

Normal Recomputation: Vertex normals are re-calculated post-displacement utilizing area-weighted averages of adjacent face normals. This is essential for correct lighting in digital renders and for generating accurate toolpaths in CAM software.

Metric Calibration: One canonical unit is defined as $100\text{mm}$ in world space, providing a bridge between the normalized unit cube and real-world dimensions.

Export Scaling: For specific physical applications, such as a $40\text{mm}$ coin, a final scale factor (e.g., $0.4$) is applied prior to STL or OBJ export. This ensures that the refined detail is appropriately sized for the final physical artifact.

6. Analytical Summary (Operational Checklist)

Stage 0: Normalization to unit cube, Loop Subdivision ($2\times$) for density, and TPS Warp alignment for topological synchronization.

Stage 1: Normal Stabilization, Hole Healing using normal vectors, $k=3$ Polynomial Alignment for scale/bias correction, and Guided Filtering for noise rejection.

Stage 2: Partitioning into a $4 \times 4$ window grid, Mask-based activation of relevant zones, and localized $\Delta D$ sampling and blending.

Stage 3: Visibility Gating to lock occluded geometry and Weighting by Normal Angle and Uncertainty to ensure data trust.

Stage 4: Edge-Length Constraint verification to prevent mesh tearing and Curvature-Aware Displacement Smoothing for structural preservation.

Stage 5: Analytical Z-axis update, Normal recalculation for shading accuracy, and Final Metric Scaling for manufacturing-ready export.